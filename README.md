# Integrating Transformer Models and Traditional Feature-Matching Techniques for Enhanced Panorama Generation and Autostitching
This repository hosts the complete suite of resources used in the research project aimed at improving panorama generation through the novel application of transformer models combined with traditional image stitching techniques.

## Project Overview

In this project, we address the challenges of sequencing the order of images and enhancing feature extraction and matching in panorama generation. We utilize a combination of Vision Transformers and traditional methods like SIFT and FLANN-based matching to achieve superior stitching accuracy and efficiency.

## Repository Contents

- `/code`: Contains all the Python scripts used for the panorama generation process.
- `/data`: Directory hosting the original set of 140 photographs used in the study.
- `/results`: Contains the generated panoramas for each of the 18 clusters identified in the research.

## Contributing

Contributions to this project are welcome. Please feel free to fork the repository, make changes, and submit pull requests. You can also open an issue if you find bugs or have suggestions for improvements.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Citation

If you use the materials from this repository in your work, please cite it as follows:

Xiang. (2024). Integrating Transformer Models and Traditional Feature-Matching Techniques for Enhanced Panorama Generation and Autostitching. GitHub repository. Available at https://github.com/qilinxiaoxiang/panorama

## Contact

If you have any questions or comments about the project, please open an issue on this GitHub repository.
